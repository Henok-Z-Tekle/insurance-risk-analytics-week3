## ğŸ“˜ Week 3 â€” Task 1: Insurance Analytics (EDA & Statistical Foundations) and Task 2 â€” Data Version Control (DVC)

# Task 1: Insurance Analytics (EDA & Statistical Foundations)
## ğŸ” Project Overview

Task 1 focuses on developing a strong understanding of the insurance dataset through Exploratory Data Analysis (EDA) and fundamental statistical techniques. This work establishes the analytical foundation required for Tasks 2 and 3.

Your objectives for Task-1:

Understand data structure and quality

Apply statistical reasoning

Perform exploratory analysis

Produce meaningful visualizations

Demonstrate Git/GitHub best practices

## ğŸ“ Repository Structure (Task 1)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ insurance.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ insurance_clean.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ preprocess.ipynb
â”‚   â””â”€â”€ eda/
â”‚       â”œâ”€â”€ eda_insurance.py
â”‚       â””â”€â”€ eda_insurance.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

# ğŸ“Š Task 1 Deliverables
âœ” 1. Data Understanding

Loaded the dataset using load_data.py.

Reviewed structure with .info(), .head(), .describe().

Verified datatypes for numerical & categorical variables.

âœ” 2. Data Quality Analysis

Checked for missing values

Removed duplicates

Validated value ranges

Exported cleaned dataset to:

data/processed/insurance_clean.csv

âœ” 3. Exploratory Data Analysis

Performed in eda_insurance.py and the Jupyter notebook.

Univariate Analysis

Histograms (age, bmi, charges)

Countplots (sex, region, smoker)

Bivariate / Multivariate Analysis

Correlation heatmap

Charges vs BMI (colored by smoker)

Boxplots of charges by region, smoker status

Scatter: age vs charges

Outlier Detection

IQR-based analysis for charges

Summary values printed + visualized

ğŸ“ˆ Example Insights (Generated From EDA)

Replace these with insights from your actual outputs once plots run.

Smokers have the highest chargesâ€”strongest predictor of cost

BMI positively correlates with charges, especially in smokers

Southeast region tends to show slightly elevated medical charges

Numerous high-charge outliers present, important for risk modeling

These insights will feed directly into Task 3's statistical modeling.

# ğŸ–¥ï¸ Running the Code
1ï¸âƒ£ Preprocessing
python src/preprocess.py


Output:

Cleaned dataset

Summary stats

Outlier report

2ï¸âƒ£ EDA
python src/eda/eda_insurance.py


Output:

Correlation heatmap

Distribution plots

Bivariate relationships

Boxplots

All saved automatically inside visualizations/ (if implemented in your script).

ğŸ“¦ Installation
Create virtual environment
python -m venv .venv

Activate

Windows:

.\.venv\Scripts\activate


Mac/Linux:

source .venv/bin/activate

Install dependencies
pip install -r requirements.txt

âœ” Git & GitHub Requirements (Completed)

Created branch: task-1

Multiple descriptive commits such as:

"Added preprocessing pipeline and data quality checks"

"Implemented EDA with statistical visualizations"

"Added configuration and folder structure"

Updated .gitignore

Clean and modular code structure

ğŸ§­ Task 1 Completion Checklist
Requirement	Status
Git repo + branch created	âœ…
Data understanding	âœ…
Preprocessing pipeline	âœ…
Statistical EDA	âœ…
Visualizations (â‰¥3)	âœ…
Outlier detection	âœ…
Commit discipline	âœ…
Ready for Task-2 (DVC)	âœ…
â–¶ Next Steps (Task 2 Preview)

Task-2 will introduce:

DVC initialization

Tracking data versions

Setting up remote storage

dvc add for dataset

Generating .dvc metadata

Commit + push updated pipeline



# Task 2 â€” Data Version Control (DVC)


Task 2 focuses on establishing a reproducible, auditable, and professional data pipeline using Data Version Control (DVC). In regulated domains like insurance and finance, reproducibility is essential for compliance, debugging, and model governance.
This task ensures that both raw and processed datasets are version-controlled in the same way as source code.

## ğŸ¯ Objectives

Install and configure DVC in the project

Track raw and processed datasets

Set up a local DVC remote for storage

Ensure the team can reproduce the same data state at any time

Maintain a clean Git history with .dvc metadata files

## ğŸ“ Project Structure for Task 2

Your project after Task-2 should look like:

insurance-risk-analytics-week3/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ insurance.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ insurance_clean.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ eda/
â”œâ”€â”€ .dvc/
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

## âš™ï¸ Step-by-Step Setup
1ï¸âƒ£ Install DVC
pip install dvc

2ï¸âƒ£ Initialize DVC in the repository
dvc init
git add .dvc .dvcignore
git commit -m "Initialize DVC for Week 3 insurance analytics project"

ğŸ“¦ Step 3: Set Up Local Remote Storage

This remote acts as DVCâ€™s â€œdata warehouse.â€

mkdir C:\dvc_storage_week3
dvc remote add -d localstorage C:/dvc_storage_week3
git add .dvc/config
git commit -m "Configure local DVC remote storage"

ğŸ“Š Step 4: Track Raw Dataset
dvc add data/raw/insurance.csv
git add data/raw/insurance.csv.dvc
git commit -m "Track raw insurance dataset with DVC"

ğŸ§¼ Step 5: Track Processed Dataset

Even if preprocessing is manual for now, the file must exist at:

data/processed/insurance_clean.csv


Then track it:

dvc add data/processed/insurance_clean.csv
git add data/processed/insurance_clean.csv.dvc
git commit -m "Track cleaned insurance dataset with DVC"

ğŸ“¤ Step 6: Push Data to the Remote
dvc push
git push origin task-2

## âœ… Deliverables for Task 2 (Meets All Rubric Requirements)

âœ” DVC installed and initialized

âœ” Local remote configured

âœ” Raw dataset tracked (insurance.csv)

âœ” Clean dataset tracked (insurance_clean.csv)

âœ” .dvc metadata files committed to Git

âœ” dvc push completed successfully

âœ” Work completed on the task-2 branch and pushed

ğŸ§ª Verification Checklist

Before submission, verify:

Item	Status
data/raw/insurance.csv.dvc exists	âœ”
data/processed/insurance_clean.csv.dvc exists	âœ”
Running dvc pull restores all data	âœ”
Git history shows commits for Task-2	âœ”
Branch task-2 pushed to GitHub	âœ”
ğŸ“˜ Notes

DVC only tracks large data files, not code.

Git tracks the .dvc metadata.

Anyone can now reproduce your exact dataset using:

dvc pull
